{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23890,
     "status": "ok",
     "timestamp": 1758553821891,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "E-rhSlYa6OrT",
    "outputId": "33a1473e-cd7c-46d0-a9b7-1e1f8f617c14"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1mpgS_a44yyG"
   },
   "outputs": [],
   "source": [
    "# Setup paths - using relative path from notebooks/ to Data/\n",
    "DATA_DIR = pathlib.Path('..') / 'Data'\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDkc-etaC_Y-"
   },
   "source": [
    "# Get metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE8bBmk5BpLU"
   },
   "source": [
    "Make API Call to xeno-canto website as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ry7QvTcL48Ki"
   },
   "outputs": [],
   "source": [
    "def get_xc_recordings(query, page):\n",
    "    \"\"\"Returns data if api call works, None if it fails\"\"\"\n",
    "\n",
    "    base_url = \"https://xeno-canto.org/api/2/recordings\"\n",
    "    params = {\"query\": query, \"page\": page}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception if the request fails (status code >= 400)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None\n",
    "\n",
    "#Example usage\n",
    "query = \"gen:Phaethornis\"\n",
    "get_xc_recordings(query, page=3)\n",
    "get_xc_recordings(query, page=4) #Only three pages of data for this genus, so this will return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5650,
     "status": "ok",
     "timestamp": 1696266494896,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "Uyko9yLP7hgX",
    "outputId": "702ad9f3-d53b-44e4-e461-4a825357b39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages: 3\n"
     ]
    }
   ],
   "source": [
    "retrieved_data = []\n",
    "page = 1\n",
    "\n",
    "while page_of_data := get_xc_recordings(query, page):\n",
    "  retrieved_data.append(page_of_data)\n",
    "  page += 1\n",
    "\n",
    "print(f\"Total number of pages: {page-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfqAjIgx7hFz"
   },
   "source": [
    "We end up with a list of 3 dictionaries, corresponding to the 3 webpages, each of which has a key \"recordings.\" This key holds an array with the recordings from that webpage. Let's concatenate these arrays to get one single array of recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wtXoLpN0Bdlz"
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "for page_data in retrieved_data:\n",
    "    records.extend(page_data[\"recordings\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TSHLb_QBmes"
   },
   "source": [
    "Each elements of this array is a dictionary containing metadata about a single recordings. We can convert our array of dictionaries to a dataframe, where each row of the dataframe corresponds to a recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1696267801308,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "XIfkMSDN68l4",
    "outputId": "e2753beb-ca60-4c61-f7ea-dd35811aa450"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sp\n",
       "ruber            167\n",
       "eurynome         124\n",
       "guy              120\n",
       "longirostris     113\n",
       "striigularis     103\n",
       "yaruqui           87\n",
       "pretrei           85\n",
       "malaris           67\n",
       "superciliosus     58\n",
       "syrmatophorus     56\n",
       "griseogularis     52\n",
       "bourcieri         47\n",
       "hispidus          29\n",
       "nattereri         25\n",
       "rupurumii         23\n",
       "squalidus         21\n",
       "philippii         19\n",
       "atrimentalis      18\n",
       "longuemareus      17\n",
       "anthophilus       16\n",
       "augusti           14\n",
       "subochraceus       9\n",
       "idaliae            7\n",
       "aethopygus         6\n",
       "koepckeae          5\n",
       "mexicanus          5\n",
       "stuarti            3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df = pd.DataFrame.from_dict(records)\n",
    "\n",
    "# Check that ids are unique identifier\n",
    "assert len(records_df.id.unique()) == records_df.shape[0]\n",
    "# Get counts of the different species\n",
    "records_df.sp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo8eAY96chcs"
   },
   "source": [
    "Let's download this dataframe, which contains metadata on our recordings, as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "83hthbIRaJn_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata to ../Data/phaethornis_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "path = DATA_DIR / 'phaethornis_metadata.csv'\n",
    "records_df.to_csv(path, index=False)\n",
    "print(f\"Saved metadata to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wQ2YdusC0pd"
   },
   "source": [
    "# Download sonograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1696266523525,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "Y3ulKFE_DauJ",
    "outputId": "020b291f-82e5-47e3-e8c8-dbfe41a81578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451    {'small': '//xeno-canto.org/sounds/uploaded/RJ...\n",
       "452    {'small': '//xeno-canto.org/sounds/uploaded/MA...\n",
       "453    {'small': '//xeno-canto.org/sounds/uploaded/BD...\n",
       "454    {'small': '//xeno-canto.org/sounds/uploaded/BD...\n",
       "455    {'small': '//xeno-canto.org/sounds/uploaded/TG...\n",
       "456    {'small': '//xeno-canto.org/sounds/uploaded/FA...\n",
       "457    {'small': '//xeno-canto.org/sounds/uploaded/TN...\n",
       "458    {'small': '//xeno-canto.org/sounds/uploaded/TN...\n",
       "459    {'small': '//xeno-canto.org/sounds/uploaded/TN...\n",
       "460    {'small': '//xeno-canto.org/sounds/uploaded/TN...\n",
       "461    {'small': '//xeno-canto.org/sounds/uploaded/AF...\n",
       "462    {'small': '//xeno-canto.org/sounds/uploaded/MA...\n",
       "463    {'small': '//xeno-canto.org/sounds/uploaded/TN...\n",
       "464    {'small': '//xeno-canto.org/sounds/uploaded/CD...\n",
       "Name: sono, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df[records_df.sp == \"augusti\"].sono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVHKY7olU4vG"
   },
   "source": [
    "Note that we are downloading the small sonograms, which are each 240x80 pixels. If we want larger images, we can change \"small\" in the following code block to \"medium\" (480x160) or \"large\" (1022x396). Whichever size we choose, we will get a sonogram of the first 10 seconds of the recording. If, on the other hand, we want the sonogram of the full recording, then we should use \"full\". However, this will be a different sized image for each recording (since it depends on the length of the recording).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78698,
     "status": "ok",
     "timestamp": 1694185060857,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "pgBlQ0MBCPaO",
    "outputId": "ddcc5f7d-e414-4da1-ab23-dff7326e127d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images for squalidus to ../Data/phaethornis_images/squalidus\n",
      "Downloading images for rupurumii to ../Data/phaethornis_images/rupurumii\n",
      "Downloading images for longuemareus to ../Data/phaethornis_images/longuemareus\n",
      "Downloading images for aethopygus to ../Data/phaethornis_images/aethopygus\n",
      "Downloading images for idaliae to ../Data/phaethornis_images/idaliae\n",
      "Downloading images for nattereri to ../Data/phaethornis_images/nattereri\n",
      "Downloading images for atrimentalis to ../Data/phaethornis_images/atrimentalis\n",
      "Downloading images for striigularis to ../Data/phaethornis_images/striigularis\n",
      "Downloading images for griseogularis to ../Data/phaethornis_images/griseogularis\n",
      "Downloading images for ruber to ../Data/phaethornis_images/ruber\n",
      "Downloading images for stuarti to ../Data/phaethornis_images/stuarti\n",
      "Downloading images for subochraceus to ../Data/phaethornis_images/subochraceus\n",
      "Downloading images for augusti to ../Data/phaethornis_images/augusti\n",
      "Downloading images for pretrei to ../Data/phaethornis_images/pretrei\n",
      "Downloading images for eurynome to ../Data/phaethornis_images/eurynome\n",
      "Downloading images for anthophilus to ../Data/phaethornis_images/anthophilus\n",
      "Downloading images for hispidus to ../Data/phaethornis_images/hispidus\n",
      "Downloading images for yaruqui to ../Data/phaethornis_images/yaruqui\n",
      "Downloading images for guy to ../Data/phaethornis_images/guy\n",
      "Downloading images for syrmatophorus to ../Data/phaethornis_images/syrmatophorus\n",
      "Downloading images for koepckeae to ../Data/phaethornis_images/koepckeae\n",
      "Downloading images for philippii to ../Data/phaethornis_images/philippii\n",
      "Downloading images for bourcieri to ../Data/phaethornis_images/bourcieri\n",
      "Downloading images for mexicanus to ../Data/phaethornis_images/mexicanus\n",
      "Downloading images for longirostris to ../Data/phaethornis_images/longirostris\n",
      "Downloading images for superciliosus to ../Data/phaethornis_images/superciliosus\n",
      "Downloading images for malaris to ../Data/phaethornis_images/malaris\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "path = DATA_DIR / 'phaethornis_images'\n",
    "\n",
    "for spec in records_df.sp.unique():\n",
    "    dest = (path/spec)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    sono_urls = [\"https://\"+sono_dict[\"small\"] for sono_dict in records_df[records_df.sp == spec].sono]\n",
    "    print(f\"Downloading images for {spec} to {dest}\")\n",
    "    download_images(dest, urls=sono_urls, preserve_filename=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127434,
     "status": "ok",
     "timestamp": 1694181871900,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "IccM10RnRzc2",
    "outputId": "c5b582df-70ab-465e-e73a-a859ca189fcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if any image failed to download\n",
    "failed = verify_images(get_image_files(path))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1Z0YCxXA0hE"
   },
   "source": [
    "# Download mp3 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpWYVSo-bpfd"
   },
   "source": [
    "This takes about 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 979849,
     "status": "ok",
     "timestamp": 1694186931801,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "hlmgigtPA3yt",
    "outputId": "1d1b97a0-2331-41aa-c336-8515c3110030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 mp3 files\n",
      "Downloaded 50 mp3 files\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m dest.mkdir(exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m, parents=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m data_file_path = (dest/\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.mp3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index % \u001b[32m50\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m mp3 files\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Deep_learning_Birds/venv/lib/python3.11/site-packages/fastcore/net.py:164\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data, headers, timeout)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reporthook: reporthook(blocknum, bs, size)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     block = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    166\u001b[39m     read += \u001b[38;5;28mlen\u001b[39m(block)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/http/client.py:460\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    464\u001b[39m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/http/client.py:583\u001b[39m, in \u001b[36mHTTPResponse._read_chunked\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    582\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m         chunk_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    585\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/http/client.py:564\u001b[39m, in \u001b[36mHTTPResponse._get_chunk_left\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk_left: \u001b[38;5;66;03m# Can be 0 or None\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    563\u001b[39m         \u001b[38;5;66;03m# We are at the end of chunk, discard chunk end\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    566\u001b[39m         chunk_left = \u001b[38;5;28mself\u001b[39m._read_next_chunk_size()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/http/client.py:631\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    625\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    626\u001b[39m \n\u001b[32m    627\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.fp.read(amt)\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    633\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/ssl.py:1311\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1309\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1310\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/ssl.py:1167\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "path = DATA_DIR / 'phaethornis_audio'\n",
    "\n",
    "for index, row in records_df.iterrows():\n",
    "    spec = row[\"sp\"]\n",
    "    id = row[\"id\"]\n",
    "    mp3_url = row[\"file\"]\n",
    "    dest = (path/spec)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    data_file_path = (dest/f\"{id}.mp3\")\n",
    "\n",
    "    urlretrieve(mp3_url, data_file_path)\n",
    "    if index % 50 == 0:\n",
    "        print(f\"Downloaded {index} mp3 files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGYJU_b_r26u"
   },
   "source": [
    "# Messing around with an image classifier. Ignore this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a59Z7AB_XWTL"
   },
   "source": [
    "First we define our data format. Specifically, we specify that\n",
    "- our model is an image classifier (Image ↦ Category)\n",
    "- how to get the items (the function `get_image_files` returns a list of image files in a given repository)\n",
    "- how to get the labels (the parent directory of the image file)\n",
    "- our train-validation split (80-20)\n",
    "- any transformation we want to do to our items (currently commented out because our untransformed images are all of the same 240x80 size anyways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "executionInfo": {
     "elapsed": 2645,
     "status": "ok",
     "timestamp": 1694181890601,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "IRU6SlzIMhlN",
    "outputId": "4f9de127-eee0-482c-cc56-55d81c6f55c6"
   },
   "outputs": [],
   "source": [
    "# dls = DataBlock(\n",
    "#     blocks=(ImageBlock, CategoryBlock),\n",
    "#     get_items=get_image_files,\n",
    "#     splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "#     get_y=parent_label\n",
    "#     , #item_tfms=[Resize((240, 80), method='squish')]\n",
    "# ).dataloaders(path, bs=32)\n",
    "\n",
    "# dls.show_batch(max_n=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 359213,
     "status": "ok",
     "timestamp": 1692224373699,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "OYcu1yGySD3Z",
    "outputId": "6c380502-0d8c-4241-f45b-42d7b815a951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 167MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.445718</td>\n",
       "      <td>3.283537</td>\n",
       "      <td>0.831897</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.769383</td>\n",
       "      <td>2.621659</td>\n",
       "      <td>0.693965</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.086149</td>\n",
       "      <td>2.551085</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.463035</td>\n",
       "      <td>2.511330</td>\n",
       "      <td>0.629310</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "# learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1692227932789,
     "user": {
      "displayName": "Evan Gorstein",
      "userId": "17010908082521250527"
     },
     "user_tz": 240
    },
    "id": "gRC0Gzgsbtiv",
    "outputId": "3a55d6cb-bc05-46d8-8aa7-8edd2eba7ad6"
   },
   "outputs": [],
   "source": [
    "# Example prediction - update path to an actual image file from your downloaded data\n",
    "# example_image = list((DATA_DIR / 'phaethornis_images').rglob('*.png'))[0]\n",
    "# im = PILImage.create(example_image)\n",
    "# learn.predict(im)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
